# these are the default settings that MARS will use if you don't override them

# relative paths to the models used for detection and pose estimation.
# if you train a new MARS model, add it to this list and give it a unique name.
# (make sure not to use any Tabs when indenting.)
all_models:
  - name: 'black mouse top'
    detection: 'models/detection/MARS_top_detection_black.pb'
    pose: 'models/pose/MARS_top_pose.pb'
  - name: 'white mouse top'
    detection: 'models/detection/MARS_top_detection_white.pb'
    pose: 'models/pose/MARS_top_pose.pb'
  - name: 'black mouse front'
    detection: 'models/detection/MARS_front_detection_black.pb'
    pose: 'models/pose/MARS_front_pose.pb'
  - name: 'white mouse front'
    detection: 'models/detection/MARS_front_detection_white.pb'
    pose: 'models/pose/MARS_front_pose.pb'
  - name: 'snacks'
    detection: 'models/detection/asap_snacks_black_top_detector.pb'
    pose: 'models/pose/asap_snacks_top_pose.pb'
  - name: 'openfield'
    detection: 'models/detection/open-all_black_top_detector.pb'
    pose: 'models/pose/open-all_top_pose.pb'

# which subjects to actually try to track in the current experiment:
subjects:
    - name: 'openfield'
      count: 1
classifiers: models/classifier

# information about your videos. Set framerate=-1 to get the framerate value from the video file.
pixels_per_cm: 1
framerate: 30

# which stages of analysis to run- pose estimation, feature extraction, and behavior classification
# feature extraction is a required step if you wish to do behavior classification, and
# pose estimation is a required step if you wish to do feature extraction.
doPose: True
doFeats: False
doActions: False

# setting multichannelAnotations to true will output predictions of each binary classifier to a separate annotation
# channel, allowing frames to potentially be labeled positive for more than one behavior.
multichannelAnnotations: True

# enable to have MARS save a video of the resulting pose estimation
doVideo: False

# overwrite any existing pose/feature/annotation files for a given video
doOverwrite: True

# cameras available for this experiment. This will determine which detection/pose model is used.
# note, feature extraction and action classification require a top-view camera, and ignore the front-view camera:
hasTopCamera: True
hasFrontCamera: False

# use multiprocessing to speed up inference; runs a different version of the code.
multiprocessing: True

# enable background-subtraction prior to mouse detection/pose estimation. This is an experimental feature, it might
# help MARS to do a better job in arenas it hasn't seen before?
bgSubtract: False

# import bounding boxes produced by a different system, and use these instead of MARS's detection step.
# If set to true, bboxType tells MARS how to unpack the user-provided boxes.
# this feature is still in development.
useExistingBBoxes: False
bboxType:

# output verbosity
verbose: 1

# max number of frames to process from a video
max_frames: 9999999
